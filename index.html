<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>FastVLM WebGPU Demo</title>
</head>
<body>
  <h2>FastVLM ONNX (WebGPU)</h2>
  <input type="file" id="imageInput" accept="image/*"/>
  <pre id="output">Loading...</pre>

  <!-- ONNX Runtime Web -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script>
    const modelUrl = "https://huggingface.co/onnx-community/FastVLM-0.5B-ONNX/resolve/main/model.onnx";

    async function run() {
      // Create session with WebGPU
      const session = await ort.InferenceSession.create(modelUrl, {
        executionProviders: ["webgpu"], // fallback to ["wasm"] if no WebGPU
      });

      console.log("Model loaded with WebGPU ✅");

      document.getElementById("output").innerText = "Model ready. Upload an image to run inference.";
    }

    run();

    // Example hook for uploaded image
    document.getElementById("imageInput").addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const img = new Image();
      img.src = URL.createObjectURL(file);
      await img.decode();

      // TODO: preprocess the image (resize, normalize, convert to tensor)
      // TODO: tokenize the prompt (e.g. "Describe this image")
      // TODO: feed into session.run()

      document.getElementById("output").innerText = "⚠️ Preprocessing/tokenization needed here!";
    });
  </script>
</body>
</html>
