<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>FastVLM WebGPU Demo</title>
</head>
<body>
  <h2>FastVLM (ONNX, WebGPU)</h2>

  <input type="file" id="imageInput" accept="image/*">
  <input type="text" id="question" placeholder="Ask about the image" size="50">
  <button id="runBtn">Run</button>

  <p><strong>Answer:</strong> <span id="output"></span></p>

  <!-- Hugging Face Transformers.js (ESM build) -->
  <script type="module">
    import { pipeline } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.0/dist/esm/transformers.min.js";

    let vlm;

    async function loadModel() {
      document.getElementById("output").innerText = "Loading model...";
      vlm = await pipeline(
        "image-text-to-text",
        "onnx-community/FastVLM-0.5B-ONNX",
        { device: "webgpu" }  // try WebGPU, fallback to CPU
      );
      document.getElementById("output").innerText = "Model loaded. Ready!";
    }

    async function runInference() {
      const fileInput = document.getElementById("imageInput");
      const question = document.getElementById("question").value;
      if (!fileInput.files[0] || !question) {
        alert("Please select an image and enter a question.");
        return;
      }

      const imageBlob = fileInput.files[0];
      document.getElementById("output").innerText = "Running...";

      const result = await vlm(imageBlob, { prompt: question });
      document.getElementById("output").innerText = result[0].generated_text;
    }

    document.getElementById("runBtn").addEventListener("click", runInference);

    // Load model on page start
    loadModel();
  </script>
</body>
</html>
